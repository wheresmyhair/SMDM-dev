# e.g., 170M non-embedding parameters MDM and 10e18 training FLOPs, 8 GPUs
python pretrain/train_mdm.py --model 170 --flops 10.